---
title: "SOC-GA 2332 Intro to Stats Lab 5 Solution"
author: "Di Zhou"
date: "3/5/2021"
output:
  html_document:
    df_print: paged
    theme: paper
    highlight: textmate
    toc: true
  pdf_document: 
    toc: true
---


<style type="text/css">

body{ 

    font-size: 16px;
    line-height: 1.7em;
    <!-- text-align: justify; -->

}

blockquote {
    padding: 10px 20px;
    margin: 0 0 20px;
    font-size: 16px;
    border: solid 1px;
}

h1 { font-size: 32px; }

h2 { font-size: 24px; }

h3 { font-size: 20px; }

</style>

<br>

---


```{r setup, include=F}
knitr::opts_chunk$set(echo = TRUE)

library(pacman)
p_load(tidyverse, foreign, stargazer, ggcorrplot, kableExtra)

```

### Part 1 Exercise

1. Simulate the data with the same relationship as specified above, only **changing the residual term from having a sd = 10 to sd = 50**. Follow the steps demonstrated above, create a dataframe and fit an OLS model to your simulated data. Create a scatterplot of your data and post the plot to Slack. *Note:* Remember to `set.seed()`! 

```{r exercise1.1}

set.seed(1234)
# Simulate IV (edu level)
edu2 <- rpois(300, lambda = 6) #rpois: Random Poisson Distribution with parameter lamda 
# Simulate DV 
earn2 <- 10 + 6*edu2 + rnorm(300, 0, 50) # add a random error using rnorm() 

# Combine dataframe
df_exercise <- tibble(x_edu = edu2, y_earn = earn2)

# Fit model
m_simu_exercise <- lm(y_earn ~ x_edu, data = df_exercise)
summary(m_simu_exercise)

# Scatterplot
df_exercise %>%
  ggplot(aes(x = x_edu, y = y_earn)) +
  geom_point(shape = 1, alpha = 0.7) +
  geom_smooth(method = "lm") +
  labs(title = "Relationship Between Years of Education and Income Rank",
       subtitle = "(using simulated data)",
       x = "Years of Edu",
       y = "Income Rank")

```


2. Then, using the formula we have learned in the lecture, hand-code the following statistics and post your answer to Slack:  
  (a) The value of TSS
  (b) $R^2$
  (c) Verify that $R^2$ = $\rho^2$
  (d) $se_{\beta_1}$
  (e) Construct the 95% confidence interval for $\beta_1$ (You can use the $\beta_1$ value reported in your OLS modeling result)

> The **sum of square error (SSE)** for Y is the sum of square errors for the fitted OLS model: $SSE = \sum\epsilon^2 = \sum(y - \hat y)^2$  
  The **total sum of sqaures (TSS)** for Y is the sum of square errors for the baseline OLS model (the "null model") that predict the value of Y without any X (the mean of Y, $\overline Y$, is used in the null model): $TSS = \sum(y - \overline y)^2$  
  **R-squared** (coefficient of determination) is the proportional reduction in squared error when fitted with the OLS model in comparison with the null model: $R^2 = \frac{TSS - SSE}{TSS}$  
  The **mean square error (MSE)**: $MSE = \frac{SSE}{n-2}$  
  The **standard error of $\beta_1$ in bivariant OLS** regression: $se_{\beta_1} = \sqrt{\frac{MSE}{\sum{(x -\overline x)^2}}}$

```{r exercise1.2} 

# Create 3 variables: x_mean, y_mean, fitted_y
df_exercise <- df_exercise %>%
  mutate(x_mean = mean(df_exercise$x_edu),
         y_mean = mean(df_exercise$y_earn),
         y_fitted = -1.402 + 8.255*x_edu)

#TSS
TSS <- (df_exercise$y_earn - df_exercise$y_mean)^2 %>% sum()
TSS

# R-squared
SSE <- (df_exercise$y_earn - df_exercise$y_fitted)^2 %>% sum()
R_sq <- (TSS - SSE)/TSS
R_sq

# Rho
rho = cor(df_exercise$y_earn, df_exercise$x_edu)
rho^2 # is equal to R_sq

# se_beta1
MSE <- SSE/(nrow(df_exercise) - 2)
denomi <- (df_exercise$x_edu - df_exercise$x_mean)^2 %>% sum() 
#Or the denominator is (n-1)sd_x^2: (nrow(df_exercise) - 1)*sd(df_exercise$x_edu)^2
se_beta1 <- sqrt(MSE/denomi)
se_beta1

# CI of se_beta1: 
#upper: 8.255 + 1.96*1.222 = 10.65012
#lower: 8.255 - 1.96*1.222 = 5.85988

```


3. Compare the scatterplot, the estimated $\beta_0$ and $\beta_1$, the $R^2$, and the $se_{\beta_1}$ in the demo OLS model output and your own simulated data model output, what do you observe? Why?  
  
  
Answer: The demo OLS model gives a much closer regression estimation than the model in exercise. Since the error term has a much larger SD in the exercise model, the result is much farther away from the true relationship due to the larger volume of the noise in the data.


---

### Part 2 Exercise 1

1. Recode using `ifelse()`: Now, let's create two 1/0 dummies for race. Create a variable `black` that equals to 1 when `race` is "black", and a variable `other` that equals to 1 when `race` is "other". Post your code on Slack.

```{r part2-exercise-recode}

# Import
earnings_df <- read.csv("data/lab5_earnings.csv", stringsAsFactors = F)

# Recode age & sex
earnings_df <- earnings_df %>%
  mutate(age_recode = ifelse(age == 9999, NA, age),
         female = ifelse(sex == "female", 1, 0))

# Recode race
earnings_df <- earnings_df %>% 
  mutate(black = ifelse(race == "black", 1, 0),
         other = ifelse(race == "other", 1, 0))

# Display
head(earnings_df, 10) %>% kbl("html") %>% kable_classic_2(full_width = F)

# save(earnings_df, file = "data/earnings_df.RData") #save for demo purpose

```

2. Reproduce this scatterplot:

![](graph/scatterplot_race.png){width=40%}


```{r part2-exercise-plot}

# Scatterplot of earnings and education, grouped by gender
earnings_df %>% 
  ggplot(aes(x = edu, y = earn, color = race)) +
  geom_point(shape = 1, alpha = 0.7) +
  geom_smooth(method = "lm", se = F)


earnings_df %>% 
  ggplot() +
  geom_point(aes(x = edu, y = earn, color = race), shape = 1, alpha = 0.7) +
  geom_smooth(aes(x = edu, y = earn, color = race), method = "lm", se = F)

#ggsave("graph/scatterplot_race.png", height = 5, width = 7)

```
---

### Part 2 Exercise 2

Now, estimate the following models and display your model results in a single table using `stargazer(m_1, m_2, ..., m_n, type="text")`. Post a screenshot of your table on Slack.

(1) Model 1: earn ~ age (baseline)
(2) Model 2: earn ~ age + edu 
(3) Model 3: earn ~ age + edu + female
(4) Model 4: earn ~ age + edu + female + race
(5) Model 5: earn ~ age + edu + female + race + edu*female

```{r exercise-2.2 models}

# Nested Models

m1 <- lm(earn ~ age_recode, 
         data = earnings_df)

m2 <- lm(earn ~ age_recode + edu,
         data = earnings_df)

m3 <- lm(earn ~ age_recode + edu + female,
         data = earnings_df)

m4 <- lm(earn ~ age_recode + edu + female + black + other,
         data = earnings_df)

m5 <- lm(earn ~ age_recode + edu + female + black + other + edu*female,
         data = earnings_df)

# save(m5, file = "data/m5_fordemo.RData") #save for demo purpose

stargazer(m1, m2, m3, m4, m5, type="text", omit.stat=c("ser", "f"))

```

---

### Part 3 Exercise 

1. In Model 5, holding other variables constant, what will be the predicted difference in estimated mean earnings for a white man and a white women?  
  
2. Holding other variables constant, what will be the predicted difference in estimated mean earnings for a white women and a black women?  
  
3. Holding other variables constant, what will be the predicted difference in estimated mean earnings for a white man and a black women?  

  
Answer:

Q1: For a white man:

$$\Delta\hat{Earnings}_{\text{wh,m}} = 6.083\cdot \text{edu} -1.571\cdot 0 - 3.128\cdot\text{edu }\cdot0 \\ = 6.083\cdot \text{edu}$$
  
  For a white woman:

$$\Delta\hat{Earnings}_{\text{wh,w}} = 6.083\cdot \text{edu} -1.571\cdot 1 - 3.128\cdot\text{edu }\cdot1 \\ = 6.083\cdot \text{edu} -1.571 - 3.128\cdot\text{edu }$$

  
  Thus the difference in $\Delta\hat{Earnings}$ between a white man and a white woman: $-1.571 - 3.128\cdot\text{edu }$  
  
Q2: For a white woman, it's demonstrated above. For a black woman:

$$\Delta\hat{Earnings}_{\text{bl,w}} = 6.083\cdot \text{edu} - 2.385\cdot1 -1.571\cdot 1 - 3.128\cdot\text{edu }\cdot1 \\ = 6.083\cdot \text{edu} - 2.385 -1.571 - 3.128\cdot\text{edu }$$
  
  
  Thus the difference in $\Delta\hat{Earnings}$ between a white woman and a black woman is:$- 2.385$
  
  
  Q3: From the equations above, we know the difference between $\Delta\hat{Earnings}_{\text{wh,m}}$ and $\Delta\hat{Earnings}_{\text{bl,w}}$ is $- 2.385 -1.571 - 3.128\cdot\text{edu } = -3.956 - 3.128\cdot\text{edu }$

---

### Part 4 Exercise

Plot the effect of `age` on `earn` according to Model 5. Post your plot on Slack.

```{r exercise-4-ploteffect }

# first, we create a dataframe with all predictor variables
# with only the key IV varies
pred_age <- tibble(age_recode = seq(20, 65, 3)) %>%         
  mutate(edu = mean(earnings_df$edu, na.rm = T),
         female = mean(earnings_df$female, na.rm = T),       
         black = mean(earnings_df$black, na.rm = T),
         other = mean(earnings_df$other, na.rm = T))

# use `predict` to predict the Y
predicted_earning_byage <- predict(m5,                      # the model you are using
                             pred_age,                # the df you use for predicting
                             interval = "confidence", # set CI
                             level = 0.95)

# bind the columns
pred_age_result <- cbind(pred_age, predicted_earning_byage)

# check df
head(pred_age_result, 10) %>% kbl("html") %>% kable_classic_2(full_width = F)
 
# Plot
pred_age_result %>% 
  ggplot(aes(x = age_recode, y = fit)) +
  geom_line() + 
  geom_ribbon(aes(ymin = lwr, ymax = upr), alpha = 0.3) +   # add 95% CI
  labs(x = "Age",
       y = "Predicted Earnings") +
  ggtitle("Predicted Earnings by Age")

```


