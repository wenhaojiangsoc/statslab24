---
title: "Problem Set 3 Solution"
author: "SOC-GA 2332 Intro to Stats (Spring 2021)"
date: 'Due: Saturday, Apr. 17th, 11:59 pm'
output:
  pdf_document: default
  html_document:
    df_print: paged
---

# Instructions

\begin{enumerate}
    \item Submit two files for each problem set. The first is a \textbf{R Markdown} (\texttt{.Rmd}) file that can be run without error from start to end. The second is a \textbf{PDF} rendered from your R Markdown file or created using \LaTeX{}. 
    \item Name your files following this convention: \texttt{[Last Name]\_ps1.Rmd} and \texttt{[Last Name]\_ps1.pdf}. 
    \item Both files should be submitted to the TA via e-mail (di.zhou@nyu.edu) before the time specified above.
    \item You are given plenty of time to work on the problem set. Please plan ahead and start early. \textbf{Except for special circumstances, the TA will not accept last-minute questions asked on the day when the problem set is due}.
    \item You are encouraged to discuss the problems with your classmates. Notice as well that we have students in this class who are not in your cohort. It would be great if you could reach out to them and work together. But \textbf{the R Markdown and PDF files that you submit have to be created on your own}.
    \item Comment on your code wherever possible and explain your ideas in detail. You will get credit for showing the steps you take and for explaining your reasoning, even if you do not get the correct final result.
\end{enumerate}

\noindent\rule{16.5cm}{0.4pt}


```{r setup}
knitr::opts_chunk$set(echo = TRUE)

# Load packages here

library(pacman)
p_load(tidyverse, stargazer, scales)

```

# Part 1 Assumptions of OLS Regression

Recall that in our first lecture on regression, we talked about the **Gauss-Markov Assumptions**. If all these assumptions are met, the OLS estimator is the **Best Linear Unbiased Estimator** (**BLUE**). In a simple bivariate case, if the "true" data-generating process is $Y = \beta_0 + \beta_1 X + \epsilon$. The Gauss-Markov Assumptions can be state as the following:  

  (a) **Linearity**: A linear relationship between $X$ and $Y$ hold in the sample.  
  (b) **Exogeneity of Predictors**: The conditional mean of the error term, given the predictor, is zero ($\mathbf{x} = [x_1, x_2, ..., x_n]^\top$ is the value vector of $X$):
  $$E[ \epsilon_i | \mathbf{x} ] = 0 \text{,   for all   }i = 1,2,...,n.$$  
  (c) **No Perfect Collinearity**: Explanatory variables cannot be perfectly correlated.  
  (d) **Homoskedasticity**:  
      - No Heteroskedasticity: The conditional variance of the error term, given the predictor, is constant: $Var[ \epsilon_i | \mathbf{x} ] = \sigma^2 \text{,   for all   }i = 1,2,...,n.$  
      - No Autocorrelation: Conditional on the predictor, the error terms are uncorrelated across the observations: $Cov[\epsilon_i, \epsilon_j | \mathbf{x} ] = 0 \text{   ,      }i \ne j.$  
  
  
**1.** [15pts] For each of the assumptions, discuss what will go wrong when the assumption is violated. Be brief in your answers. *Note*: In addition to class materials, you can learn more about these assumptions in the [$\text{\underline{Wikipedia article}}$](https://en.wikipedia.org/wiki/Gauss%E2%80%93Markov_theorem) on the Gauss–Markov theorem, particularly the "Gauss–Markov theorem as stated in econometrics" section. (You can skip all the mathematical proofs and remarks.)  
  
  **Answers:** 
(a) Linearity: We would fit the wrong model! Our model would not capture the true relationship between $Y$ and $X$.  

(b) Exogeneity of Predictors: The OLS estimator would be biased.

(c) No Perfect Multicollinearity: Regression coefficients cannot be calculated.  

(d) Homoskedasticity: The OLS estimator would still be unbiased but the estimator for the standard error of the regression coefficients will be wrong. So, (1) our test-statistics would not follow a t-distribution (or Normal) distribution we assume it to follows, and (2) our hypothesis tests will not have the correct $\alpha$-level, i.e., the probability of falsely rejecting a true null hypothesis will no longer be $\alpha$. Equivalently, the probability with which our 95% confidence interval contain the true parameter will no longer be .95.
  

**2.** [5pts] Let $\beta_0 = -0.25$, $\beta_1 = 1.2$, $X \sim \Gamma(5, 4)$, and $\epsilon \sim Normal(0, 1)$. Here, $\Gamma(\alpha, \psi)$ denotes the Gamma distribution with shape parameter $\alpha$ and rate parameter $\psi$. (You can search how to use R to simulate from this distribution.)  
  Simulate a dataset of size $n = 3,000$ from this process in which all of the assumptions you've discussed above hold. Estimate a OLS model and plot regression diagnostics of this model.  
  
  
```{r }

# sample size
n = 3000
# parameters
beta0 = -.25
beta1 = 1.2

# simulate values
set.seed(1234)
x = rgamma(n, 5, 4)
e = rnorm(n, 0, 1)
y = beta0 + beta1 * x + e

# create dataset
dat = tibble(y = y, x = x)

# model
m_dat <- lm(y ~ x, dat)
summary(m_dat)

# diagnostics
par(mfrow = c(2,2))
plot(m_dat)


```

**Bonus Question** [10pts]: From assumption (a), (b) and (d), choose one assumption and simulate a data that violates that assumption (all other assumptions should be satisfied). Create a plot which illustrates how the violation of the assumption affects the regression results. This can be a scatterplot with both the "true" and "false" OLS lines, a sampling distribution of the OLS estimator (comparing your estimate model results with actual simulations), or anything that shows how the violation leads us to false decisions if we assume the assumption is true. (The point is to demonstrate a contrast between the "true" and the "false", not just diagnostics of the "false".)  

When simulating data, you don't have to use the parameters set in the previous problem.  

*Hint*: You can search how to use `+ stat_function()` to plot a nonlinear line when plotting with `ggplot()`, or search how to use the base R functions such as `plot()` and `curve()`.

```{r }

# Linearity Assumption Violated

#If true relationship is log-linear (nonlinear)
y1 = beta0 + 5 * log(x) + e

#New data
dat1 = tibble(y = y1, x = x) 

# OLS model with linear assumption
m_dat1 <- lm(y ~ x, dat1)

# Diagnostics: Note the first residual vs. fitted plot
par(mfrow = c(2,2))
plot(m_dat1)

# Plot
dat1 %>%
  ggplot() +
  geom_point(aes(x = x, y = y), alpha = 0.2, shape = 1) +
  # Plot true non linear relationship
  stat_function(aes(color = "True Relationship"), 
                fun = function(x) beta0 + 5 * log(x)) + 
  # Plot the linear OLS line
  geom_abline(aes(color = "Estimated OLS", 
                  intercept = m_dat1$coefficients[1], 
                  slope = m_dat1$coefficients[2])) +
  scale_colour_manual(name = "", values = c("darkmagenta", "darkcyan")) 



```


```{r }
# Exogeneity Assumption Violated:

# let x_cor be a function of e. 
# This will induce some correlation between x_cor and e
x_cor = 0.25 * e + runif(n, -1, 1)

# check that these variables are indeed correlated cor(x_cor, e)

# simulate data
y2 = beta0 + beta1*x_cor + e

# make dataframe
dat2 = tibble(x = x, y = y2) 

# OLS model
m_dat2 <- lm(y ~ x, dat2)

# Plot 
dat2 %>%
  ggplot() +
  geom_point(aes(x = x, y = y2),  alpha = 0.2, shape = 1) +
  geom_abline(aes(color = "True OLS",
              intercept = beta0, 
              slope = beta1)) + 
  geom_abline(aes(color = "Estimated OLS",
              intercept = m_dat2$coefficients[1], 
              slope = m_dat2$coefficients[2] 
              )) +
  scale_colour_manual(name = "", values = c("darkmagenta", "darkcyan")) 



```

```{r }

# Homoskedasticity Violated

# sample error term where variance of error is function of x 
# note: this is different from x and e being correlated! 
het_e = rnorm(n, mean = 0, sd = 0.5 * x)

# simulate data
y3 = beta0 + beta1 * x + het_e

# get regression results 
sum_fit3 = summary(lm(y3 ~ x))

# save estimated standard error
se = coef(sum_fit3)[2, 2]
est_beta = sum_fit3$coefficients[2]


# simulate sampling distribution of the coefficients
n_sim = 1000
res = matrix(NA, nrow = n_sim, ncol = 2)

for (s in 1:n_sim) {
  
# simulate error
het_e_sim = rnorm(n, mean = 0, sd = 0.5 * x) 
# simulate outcome
y_sim = beta0 + beta1 * x + het_e_sim
# save regression coefficients
res[s, ] = coef(lm(y_sim ~ x))
}

# histogram of beta1
hist(res[, 2],
     main = expression(paste("Sampling Distribution of ", hat(beta)[1])),
     freq = F,
     xlim = c(1.05, 1.35),
     ylim = c(0, 25),
     col = scales::alpha("grey", .8), 
     border = "white",
     breaks = 50,
     xlab = expression(hat(beta)[1])
     )

# overlay theoretical distribution based on CLT
# note: assuming mean equal true beta1 to make comparison easier
curve(dnorm(x, mean = beta1, sd = se), add = T, col = "darkmagenta")

# true coefficient
abline(v = beta1, col = "darkcyan", lty = 2)

# add legend
legend("topright",
       legend = c("Simulated sampling distribution\nunder heteroskedasticity",
                  "Theoretical distribution\nassuming equal variance",
                  "True parameter value"),
       pch = c(15, NA, NA),
       lty = c(NA, 1, 2),
       col = c(scales::alpha("grey", .8), "darkmagenta", "darkcyan"),
       y.intersp = 1.5, 
       bty = "n",
       cex = .9)

```

# Part 2 Causality

A study on COVID-19 constructed a "COVID risk factor" score based on the COVID infection rate of a given area (defined by zip code).  

A researcher wants to estimate the effect of having a vaccination center in the area on that area's COVID risk factor score. She compiled a dataset that contains each area's COVID risk factor score and whether the area has a vaccination center. She then estimated the effect of having a vaccination center using the "naive estimator" we discussed in class.  

You noted that the quality of information residents have about COVID and the vaccine can be a confounding variable that affects both the area's infection rate and whether there is a vaccination center in the area. Assume that you are able to estimate the relationships this "informedness"  confounder (`info`) and the original "vaccination center" predictor (`vaccine`) have with the COVID risk factor score (`covid_risk`), which can be simulated using the following code (`n` is sample size):

```
set.seed(1234) # set the same seed to ensure identical results
e = rnorm(n, 0, 0.5)
covid_risk = rescale( 0 - 7*vaccine - 2*info + e, to = c(0, 100))

```

**1.** [5pts] Import the data `covid.csv`, according to the counterfactual framework, constructing a counterfactual "risk factor" in the dataframe. 

```{r }

covid_df <- read.csv("covid.csv")

# Create counterfactual
set.seed(1234)
n = nrow(covid_df)
e <- rnorm(n, 0, 0.5)
covid_df_new <- covid_df %>%
  mutate(vaccine_ctf = ifelse(vaccine == 1, 0, 1),
         covid_ctf = rescale(0 - 7*vaccine_ctf - 2*info + e, to = c(0, 100)))


# observed_treatment
mean(covid_df_new[covid_df_new$vaccine == 1,]$covid_risk)
# observed_control
mean(covid_df_new[covid_df_new$vaccine == 0,]$covid_risk)
# counterfactual_treatment
mean(covid_df_new[covid_df_new$vaccine == 1,]$covid_ctf)
# counterfactual_control
mean(covid_df_new[covid_df_new$vaccine == 0,]$covid_ctf)


```

**2.** [10pts] Fill out the table below (round to 1 decimal points):

Group                     |     $Y^T$            |   $Y^C$
--------------------------|----------------------|----------------------
Treatment Group ($D = 1$) | $E[Y^T|D = 1] = 41.8$    |   $E[Y^C|D = 1] = 58.1$
Control Group ($D = 0$)  |   $E[Y^T|D = 0] = 49.7$       |  $E[Y^C|D = 0] = 67.3$

  
  
  
**3.** [15pts]Estimate the following:

(a) The Naive Estimator of ATE  
  
  Naive ATE = $E[Y^T|D = 1] - E[Y^C|D = 0] = 41.8 - 67.3 = -25.5$
  
(b) Treatment Effect on the Treated  
  
  ATT = $E[Y^T|D = 1] - E[Y^C|D = 1] = 41.8 - 58.1 = -16.3$

(c) Treatment Effect on the Control  

  ATC = $E[Y^T|D = 0] - E[Y^C|D = 0] = 49.7 - 67.3 = -17.6$  
  
(d) Selection Bias  

  $E[Y^C|D = 1] - E[Y^C|D = 0] = 58.1 - 67.3 = -9.2$
  

**4**. [15pts] Write a non-technical, short summary reporting your results in response to the above mentioned researcher who used the naive estimation. Imagine that you are explaining this to an audience who may not be familiar with the specific terminologies of the counterfactual framework (such as ATE or Treatment Effect on the Treated), but is interested in your substantive findings.

[Your Answer Here]  
  The previous research claims that having a vaccination center in an area will reduce that area's COVID risk score by 25.5 points. However, that research failed to consider the impact of a potential confounder, namely the quality of information residents have about COVID and the vaccine. This confounder not only increases the chances for an area to have an vaccination center, but also directly lowers the risk of infection among local residents.  
  
  By taking into account of this confounder, I find that there exists a baseline difference at about 9.2 points in COVID risk score between areas with high and low quality information, even if both kinds of areas have no vaccination center. My study suggests that the actual effect of having a vaccination center in an area is much less than previously claimed. The average net effect of having a vaccination center on reducing COVID risk score should be around 16 to 18. Specifically, my estimate suggests a 16.3 reduction for areas with high quality information and a 17.6 reduction for areas with low quality information. 

  

# Part 3 Linear Probability Model and Logistic Regression 

`admin.csv` contains a dataset of graduate school admission results with the following variables:

Variable Name|  Variable Detail
------------|----------------------------
 `admit`| Admission Dummy (Admitted is 1) 
 `gre`  | GRE score percentile
 `gpa`| GPA percentile
 `rank`   |  Institution Tier (Tier 1 to 4)
 

**1**. [10pts] Import `admin.csv` to your R environment. Estimate (a) a linear probability model and (b) a logistic regression model to predict the probability of being admitted based on the applicant's GRE, GPA, and institution tier. Display the two modeling results in a table.

```{r, results='asis'}

# Import
admin_df <- read.csv("admin.csv")

# LPM 
m1 <- lm(admit ~ gre + gpa + as.factor(rank), data = admin_df)

# Logistic Regression
m2 <- glm(admit ~ gre + gpa + as.factor(rank), data = admin_df, family = "binomial")

# Get effect on odds
# options(scipen = 999) # set to display digits
# exp(coef(m2))

stargazer(m1, m2, type = "latex")


```

**2**. [10pts] In one or two paragraphs, summarize your modeling result for each model.
  
  The modeling results suggest that GRE, GPA, and institutional ranking all have positive effect on the probability of a candidate being admitted. And the effect of all predictors in these two models are statistically significant.  
  
  In the linear probability model (LPM), holding others at their constant, one unit increase in one's GRE score will lead to a 0.04% increase in one's chance of admission. Holding others at their constant, one unit increase in one's GPA results in a 16% increase. Compared to candidates from Tier 1 institutions, those coming from Tier 2 will have 16.2% less chance, while holding others at constant. For Tier 3, the chance further decrease to having a 29.1% difference from those from Tier 1. This difference further widens to 32.3% for candidates coming from Tier 4 schools. (All compared to Tier 1 with other variables held at constant.) Logistic regression provides similar results. One unit GRE score increase will lead to a slight increase in the odds of being admitted, whereas one unit increase in GPA will multiply the odds by 2.23. Similar to LPM results, compared to candidates from Tier 1 schools the odds is deflated as school tier gets lower.
  

**3**. [15pts] Plot the predicted probability of admission based on one's GPA percentile and institution rank (holding GRE at the mean) for the logistic regression model. For the purpose of this exercise, please set the value of `gpa` to range from 1 to 4. Make sure to add appropriate title and labels to your figure.

```{r }

# create new dataset for predictions: GPA for admission by school rank
pred_dat <- tibble(
  gre = mean(admin_df$gre),
  gpa = rep(seq(1, 4, length.out = 20), 4),
  rank = factor(rep(1:4, each = 20))
  )

# predict the logit and standard errors
yhat_logit <- predict(m2, 
                      newdata = pred_dat,
                      type = "link",
                      se.fit = TRUE) %>%
  as_tibble() %>%
  select(fit, se.fit) %>%
  mutate(lwr = fit - 1.96 * se.fit,  # calculate 95% CI for logits 
         upr = fit + 1.96 * se.fit) %>%
  select(-se.fit)


# define function g
inv_logit = function(z) {
  1 / (1 + exp(-z))
}

# Transform y to probability
yhat_prob <- yhat_logit %>%
  mutate_at(c("fit", "lwr", "upr"), inv_logit)

# Combine data
pred_df_logit <- cbind(pred_dat, yhat_prob)

# Plot predicted probabilities (save plot in object l_plot)
pred_df_logit %>%
  ggplot(aes(x = gpa, y = fit, fill = rank)) +
  # predicted probabilities
  geom_line(aes(color = rank)) + 
  # 95% CI
  geom_ribbon(aes(ymin = lwr, ymax = upr),
              alpha = .5) +
  # add horizontal lines at zero and one
  geom_hline(yintercept = c(0, 1), linetype = 2) +
  # add vertical lines at values of pid
  geom_vline(xintercept = seq(1, 4, 0.5), linetype = 3, col = "grey") +
  labs(title = "Predicted Probability of Admission by GPA and Institution Rank") +
  # change theme
  theme_classic() 
```

# Part 4 (Not Graded) Final Replication Project

At this point, you should complete most of the data cleaning and start replicating the descriptive tables and figure. You can submit an additional PDF file if you have made progress in replication Table A1a, Table A1b, and Figure 1.  


